{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How do I increase the cell width of the Jupyter/ipython notebook in my browser? https://stackoverflow.com/a/34058270\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from datetime import date,datetime\n",
    "dateStamp = date.today().strftime(\"%y%m%d\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps: goal: characterize the match score between poses & stereotypic pattern \n",
    "\n",
    "**data input** \n",
    "    \n",
    "    read_individualRating_from_condition(scenarioAlone)\n",
    "    \n",
    "**common across analyses**\n",
    "    \n",
    "    represent_pose_with_ActionUnit_pattern\n",
    "    compute_median_ratings\n",
    "    \n",
    "    compute_mean_estimates_and_CI\n",
    "\n",
    "**reliability analysis**\n",
    "\n",
    "    assign_stereotypicEmotionCategory_to_each_scenario ~ retrieveHighestRatedEmotionCategoryForEachScenario\n",
    "        define_assignment_criteria\n",
    "            emotionCategory_with_highest_median_rating \n",
    "                break_tie_basedOn_narrower_interquartileRange \n",
    "                    implementation:\n",
    "                        ~ intermediate step: compute JointProxyWhereHighestRatedCategoryIsMinimumValue = dfMedianProxy+dfIQR\n",
    "                        ~ extractCategoryWithHighestMedianSmallestIQR\n",
    "\n",
    "    compare_between_each_pose_and_stereotypicPattern_using_matchScore \n",
    "        define_comparison_metric\n",
    "        compute_matchScore_using_defined_metric\n",
    "        \n",
    "    \n",
    "    +characterize_matchScore_using_statisticalMethods        \n",
    "\n",
    "**specificity_analysis** \n",
    "\n",
    "    represent_pose_with_ActionUnit_pattern ~ dfAU_binaryActivation=obtainActionUnitActivationDataframeBasedOn(df_original,ACTIVATION_THRESHOLD)  \n",
    "    \n",
    "    assign_poses_into_emotion_category_by_AUstereotypes\n",
    "        pick_matching_poses_forEach_AUstereotypes_variants \n",
    "            compute_match_score_for_all_poses_against_a_variant\n",
    "            pick_poses_with_score_above_specificityThreshold\n",
    "        combine_matching_poses_across_variants_of_AU_stereotypes\n",
    "        retain_unique_set_of_matching_poses_by_removing_overlaps\n",
    "        \n",
    "    determine_if_pose_specific_to_assignged_emotion_category\n",
    "        is_pose_NOT_specific_to_assigned_emotion_category\n",
    "            is_rating_of_assigned_emotion_category_BELOW_presenceThreshold\n",
    "            is_rating_of_another_emotion_category_ATLEAST_presenseThreshold    \n",
    "        \n",
    "    compute_false_positive_rate_for_each_emotion_category\n",
    "        count_total_poses_assigned_to_emotion_category\n",
    "        count_false_positive_poses_per_assigned_to_emotion_category\n",
    "        false_positive = count_false_positive_poses_per_assigned_to_emotion_category/ count_total_poses_assigned_to_emotion_category\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher():\n",
    "    def __init__(self,AU_PATTERN_FILE='refAU_13_ekman_plusICPonly'):\n",
    "            ### MAIN ###\n",
    "        self.compute_match = {\n",
    "            'method1' : self.compute_match_score_method1,\n",
    "            'method2' : self.compute_match_score_method2,\n",
    "            'method1_sim_addAU' : self.compute_match_score_method1_simulate_additionalAU_baseline_median,\n",
    "            'method2_sim_addAU' : self.compute_match_score_method2_simulate_additionalAU_baseline_median,\n",
    "            'method1_allAddAU': self.compute_match_score_method1_additionalAU_alwaysOn,\n",
    "            'method2_allAddAU': self.compute_match_score_method2_additionalAU_alwaysOn,\n",
    "            'method1_sim_addAU_baseline_max' : self.compute_match_score_method1_simulate_additionalAU_baseline_max,\n",
    "            'method2_sim_addAU_baseline_max' : self.compute_match_score_method2_simulate_additionalAU_baseline_max,\n",
    "        }\n",
    "\n",
    "        from facsStereotypes import AUdataReadWrite\n",
    "        rw=AUdataReadWrite()\n",
    "        self.STEREOTYPES = rw.load_AUdata_into_currentFormat(AU_PATTERN_FILE)\n",
    "        \n",
    "        self.compute_matchScore_across_stereotypeVariants={\n",
    "            'median': self.compute_median_matchScore_across_stereotypeVariants,\n",
    "            'max' : self.compute_max_matchScore_across_stereotypeVariants,\n",
    "            'median-cordaro': self.compute_median_matchScore_across_stereotypeVariants_addCordaroUSA,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_match_score_method1(target,ref,v=False): \n",
    "        ''' #method 1 - coderReliabilityMethod: jointly activated AU x 2 / all activated AU across target & reference pattern '''\n",
    "        print('method1') if(v) else ''\n",
    "        try:\n",
    "            return len(set(target).intersection(set(ref)))*2/(len(target)+len(ref))   \n",
    "        except:\n",
    "            return 1 # fully matched - neutral\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_match_score_method2(target,ref,v=False): \n",
    "        ''' #method 2 - directMatchMethod: overlapped activated AU / activated AU of reference pattern '''\n",
    "        print('method2') if(v) else ''\n",
    "        return len(set(target).intersection(set(ref)))/len(ref)\n",
    "\n",
    "\n",
    "    ### CONSIDERING ADDITION AU ###\n",
    "    @staticmethod\n",
    "    def get_number_of_AUs_above_27(ref): AU27vec=[i for i in ref if i <=27];return len(ref)-len(AU27vec)\n",
    "    \n",
    "    def compute_match_score_method1_simulate_additionalAU_baseline_median(self,target,ref,v=False,AU_BASELINE=.104):\n",
    "        return self.compute_match_score_method1_simulate_additionalAU(target,ref,v=False,AU_BASELINE=AU_BASELINE)\n",
    "    \n",
    "    def compute_match_score_method2_simulate_additionalAU_baseline_median(self,target,ref,v=False,AU_BASELINE=.104):\n",
    "        return self.compute_match_score_method2_simulate_additionalAU(target,ref,AU_BASELINE=AU_BASELINE,v=False)\n",
    "    \n",
    "    def compute_match_score_method1_simulate_additionalAU_baseline_max(self,target,ref,v=False,AU_BASELINE=.651):\n",
    "        return self.compute_match_score_method1_simulate_additionalAU(target,ref,v=False,AU_BASELINE=AU_BASELINE)\n",
    "    \n",
    "    def compute_match_score_method2_simulate_additionalAU_baseline_max(self,target,ref,v=False,AU_BASELINE=.651):\n",
    "        return self.compute_match_score_method2_simulate_additionalAU(target,ref,v=False,AU_BASELINE=AU_BASELINE)\n",
    "\n",
    "    def compute_match_score_method1_simulate_additionalAU(self,target,ref,AU_BASELINE,v=False):\n",
    "        ''' #method 1, simulate activated AU above 27 (1000 simulations), randomly assigned whether AU above 27 within stereotype pattern is activated in target pattern'''\n",
    "        n27=self.get_number_of_AUs_above_27(ref)\n",
    "\n",
    "        def randomize_number_of_AUoverlap_above_AU27(totalAUabove27,AU_BASELINE): \n",
    "            return np.sum(np.random.rand(1000,totalAUabove27)<AU_BASELINE,axis=1)\n",
    "        o27Arr= randomize_number_of_AUoverlap_above_AU27(n27,AU_BASELINE)\n",
    "\n",
    "        def computeMatch(n): return (len(set(target).intersection(set(ref)))*2+n*2)/(len(target)+len(ref)+n+n27)    \n",
    "        ms= [computeMatch(n) for n in o27Arr]\n",
    "\n",
    "        return np.median(ms)\n",
    "\n",
    "    def compute_match_score_method2_simulate_additionalAU(self,target,ref,AU_BASELINE,v=False):\n",
    "        ''' #method 2, simulate activated AU above 27 (1000 simulations), randomly assigned whether AU above 27 within stereotype pattern is activated in target pattern '''\n",
    "        n27=self.get_number_of_AUs_above_27(ref)\n",
    "\n",
    "        def randomize_number_of_AUoverlap_above_AU27(totalAUabove27,AU_BASELINE = AU_BASELINE): \n",
    "            return np.sum(np.random.rand(1000,totalAUabove27)<.65,axis=1)\n",
    "        o27Arr= randomize_number_of_AUoverlap_above_AU27(n27,AU_BASELINE) \n",
    "\n",
    "        def computeMatch(n): return (len(set(target).intersection(set(ref)))+n)/(len(ref)+n27)   \n",
    "        ms= [computeMatch(n) for n in o27Arr]\n",
    "\n",
    "        return np.median(ms) \n",
    "\n",
    "    def compute_match_score_method1_additionalAU_alwaysOn(self,target,ref,v=False):\n",
    "        n27=self.get_number_of_AUs_above_27(ref)\n",
    "        return (len(set(target).intersection(set(ref)))*2+n27*2)/(len(target)+len(ref)+n27*2)  \n",
    "\n",
    "    def compute_match_score_method2_additionalAU_alwaysOn(self,target,ref,v=False):\n",
    "\n",
    "        n27=self.get_number_of_AUs_above_27(ref)\n",
    "        return (len(set(target).intersection(set(ref)))+n27)/(len(ref)+n27)      \n",
    "\n",
    "    def compute_matchScore(self,target,ref,method='method1',isBinary=False,BinaryTHRES=.7): \n",
    "        '''\n",
    "            @param method\n",
    "            method1: coderReliabilityMethod: jointly activated AU x 2 / all activated AU across target & reference pattern \n",
    "            method2: directMatchMethod: overlapped activated AU / activated AU of reference pattern     \n",
    "            method1_sim_addAU: method1 + simulate activated AU above 27 (1000 simulations), randomly assigned whether AU above 27 within stereotype pattern is activated in target pattern\n",
    "            method2_sim_addAU: method2 + simulate activated AU above 27 (1000 simulations), randomly assigned whether AU above 27 within stereotype pattern is activated in target pattern\n",
    "            method1_allAddAU: method1 + assume AU above 27 always on\n",
    "            method2_allAddAU: method2 + assume AU above 27 always on\n",
    "        '''\n",
    "        r=self.compute_match[method](target,ref)\n",
    "        return (r>BinaryTHRES)*1 if(isBinary) else r\n",
    "    \n",
    "    def compute_median_matchScore_across_stereotypeVariants(self,target,refEmoCat,method):\n",
    "        ''' \n",
    "            For a source where an emotion category does not have a Stereotype\n",
    "            Assign that Emotion Category the value of -1 and return a matchscore of -1\n",
    "            Filter this out in the final data since it will affec the median\n",
    "        '''\n",
    "        matchScores = list()\n",
    "        for eachRef in self.STEREOTYPES[refEmoCat].values():\n",
    "            if(eachRef[0]==-1):\n",
    "                matchScores.append(-1)\n",
    "            else:\n",
    "                matchScores.append(self.compute_match[method](target,eachRef))\n",
    "        return np.median(np.asarray(matchScores))\n",
    "\n",
    "    def compute_median_matchScore_across_stereotypeVariants_addCordaroUSA(self,target,refEmoCat,method,BinaryTHRES=.7):\n",
    "        matchScores = [self.compute_matchScore(target,eachRef,method) for eachRef in self.STEREOTYPES[refEmoCat].values()]\n",
    "\n",
    "        from facsStereotypes import REF_AU_USA_VEC as CORDARO_USA_STEREOTYPES\n",
    "        matchScores_Cordaro = [self.compute_matchScore(target,eachRef,method,isBinary=True,BinaryTHRES=BinaryTHRES) for eachRef in CORDARO_USA_STEREOTYPES[refEmoCat].values()]\n",
    "        return np.median(np.asarray(matchScores+matchScores_Cordaro))\n",
    "\n",
    "    def compute_max_matchScore_across_stereotypeVariants(self,target,refEmoCat,method):\n",
    "        matchScores = [self.compute_match[method](target,eachRef) for eachRef in self.STEREOTYPES[refEmoCat].values()]\n",
    "        return np.max(np.asarray(matchScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer():\n",
    "    EMO_CAT=['Amusement', 'Anger', 'Awe', 'Contempt', 'Disgust', 'Embarrassment', 'Fear', 'Happiness', 'Interest', 'Pride', 'Sadness', 'Shame', 'Surprise']\n",
    "    CATEGORY=['None','Weak','Moderate','Strong']\n",
    "    AU_PATTERN_TYPES= {\n",
    "            'original': 'refAU_13_ekman',\n",
    "            'withICP' : 'refAU_13_ekman_plusICPonly',\n",
    "            'ICP_and_USA' : 'refAU_13_Cordaro_ICPandUSA',\n",
    "            'USAonly' : 'refAU_13_Cordaro_onlyUSA',\n",
    "            'ICPalone': 'refAU_13_Cordaro_onlyICP',\n",
    "        }\n",
    "    TIE_BREAKING_METHODS = [\n",
    "        'method1_highest_matchScore',\n",
    "        'method2_mean_sd',\n",
    "        'method3_randomly_selected'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 AU_PATTERN_TYPE=None,\n",
    "                 METHOD=None,\n",
    "                 RATING_INTENSITY=None,\n",
    "                 TIE_BREAKER_MATCH_SCORE=None,\n",
    "                 ACTIVATION_THRESHOLD=None,\n",
    "                 SPECIFICITY_THRESHOLD=None,\n",
    "                 USE_2nd_TOP_CATEGORY=None,\n",
    "                 SPECIFICITY_categories=None):   \n",
    "        self.__load_data(AU_PATTERN_TYPE,RATING_INTENSITY)   \n",
    "        self.__initialize_vars_reliability(METHOD,USE_2nd_TOP_CATEGORY,TIE_BREAKER_MATCH_SCORE)\n",
    "        self.__initialize_vars_specificity(ACTIVATION_THRESHOLD,SPECIFICITY_THRESHOLD,SPECIFICITY_categories)\n",
    "        \n",
    "        self.FLAG_PERFORMED={'reliability': False, 'specificity': False}\n",
    "        \n",
    "        self.check_and_perform_analysis = {\n",
    "            'reliability': self.perform_reliability_analysis,\n",
    "            'specificity': self.perform_specificity_analysis,\n",
    "        }\n",
    "    \n",
    "    def check_and_perform_analysis_(self,TYPE='reliability'):\n",
    "        if(self.FLAG_PERFORMED[TYPE] is not True):\n",
    "            print('Performing analysis: ',TYPE)\n",
    "            self.check_and_perform_analysis[TYPE]()\n",
    "        else:\n",
    "            print('...' + TYPE + ' analysis already performed. Skipping')\n",
    "           \n",
    "    def perform_specificity_analysis(self):\n",
    "        dfSELECTED = self.dfAUlists[self.dfAUlists.index.isin(self.SELECTED)]\n",
    "        dfs = self.__assign_poses_into_emotion_category_by_AUstereotypes_into_dict_of_dataframes(dfSELECTED,self.SPECIFICITY_THRESHOLD)        \n",
    "        bool_Dfs=self.__assign_true_if_pose_specific_to_assignged_emotion_category_into_dict_of_booleanDataframes(dfs,self.dfMedian)\n",
    "\n",
    "        \n",
    "        df_stat=self.__compute_specificity_statistics_into_dataframe(bool_Dfs)\n",
    "        \n",
    "#         self.dfs = dfs\n",
    "#         self.bool_Dfs = bool_Dfs\n",
    "        self.FLAG_PERFORMED['specificity'] = True\n",
    "        return df_stat\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def perform_reliability_analysis(self,USE_2nd_TOP_CATEGORY=None):        \n",
    "        self.matchScores = self.__compute_604_times_13_matchscores(self.dfAUlists,self.METHOD,self.AU_PATTERN_TYPE,BinaryTHRES=1) \n",
    "        if(self.TIE_BREAKER_MATCH_SCORE):\n",
    "            self.dfTopEmo = self.__get_topEmo()  \n",
    "        else:\n",
    "            self.dfTopEmo = self.__get_topEmo_basedOn_()\n",
    "        \n",
    "        self.USE_2nd_TOP_CATEGORY =  USE_2nd_TOP_CATEGORY if(USE_2nd_TOP_CATEGORY is not None) else self.USE_2nd_TOP_CATEGORY\n",
    "        if(self.USE_2nd_TOP_CATEGORY): \n",
    "            print('USING 2nd TOP CATEGORY')\n",
    "            self.dfTopEmo = self.__get_2ndtopEmo()\n",
    "                \n",
    "        self.reliabilityScore = self.__compute_reliability_score()\n",
    "        \n",
    "        self.FLAG_PERFORMED['reliability'] = True\n",
    "       \n",
    "    def __load_data(self,AU_PATTERN_TYPE,RATING_INTENSITY):     \n",
    "        self.AU_PATTERN_TYPE = AU_PATTERN_TYPE or self.AU_PATTERN_TYPES['withICP']  \n",
    "        self.matcher = Matcher(AU_PATTERN_FILE=self.AU_PATTERN_TYPE)\n",
    "        \n",
    "        self.dfAUlists = self.__load_AU_data()\n",
    "        self.df_so = self.__load_rating_data()\n",
    "        \n",
    "        self.RATING_INTENSITY = RATING_INTENSITY or 0\n",
    "        self.SELECTED=self.____select_scenarios_with_minimum_rating_intensity()   \n",
    "\n",
    "    def __initialize_vars_reliability(self,METHOD,USE_2nd_TOP_CATEGORY,TIE_BREAKER_MATCH_SCORE):\n",
    "        self.METHODS=['method1', 'method2', 'method1_sim_addAU', 'method2_sim_addAU', 'method1_allAddAU', 'method2_allAddAU']     \n",
    "        self.METHOD = METHOD or 'method1_allAddAU'\n",
    "        \n",
    "        self.TIE_BREAKER_MATCH_SCORE = TIE_BREAKER_MATCH_SCORE or False\n",
    "        \n",
    "        self.USE_2nd_TOP_CATEGORY = USE_2nd_TOP_CATEGORY or False\n",
    "        \n",
    "        self.CORDARO_THRESHOLD = 0.7 #any values between (0,1)\n",
    "    \n",
    "    def __initialize_vars_specificity(self,ACTIVATION_THRESHOLD,SPECIFICITY_THRESHOLD,SPECIFICITY_categories):\n",
    "        self.ACTIVATION_THRESHOLD=ACTIVATION_THRESHOLD or 0\n",
    "        self.SPECIFICITY_THRESHOLD=SPECIFICITY_THRESHOLD or 0.4\n",
    "        \n",
    "        DEFAULT_SPECIFICITY_categories = ['Anger', 'Awe', 'Contempt', 'Disgust', 'Fear', 'Happiness', 'Interest', 'Sadness', 'Surprise']\n",
    "        self.SPECIFICITY_categories = SPECIFICITY_categories if(SPECIFICITY_categories is not None) else self.EMO_CAT\n",
    "          \n",
    "        self.REF_AU_VEC = {emo : patterns for emo,patterns in self.matcher.STEREOTYPES.items() if emo in self.SPECIFICITY_categories}\n",
    "        \n",
    "        self.dfMedian = self.df_so.groupby('survey_questions_id').median()[self.EMO_CAT]\n",
    "    \n",
    "    ##=========================================================================\n",
    "    def get_current_config(self):\n",
    "        return {\n",
    "            'METHOD': self.METHOD,\n",
    "            'AU_PATTERN_TYPE': self.AU_PATTERN_TYPE,\n",
    "            'RATING_INTENSITY': self.RATING_INTENSITY,\n",
    "        }\n",
    "        \n",
    "        ##\n",
    "        \n",
    "    def count_topEmo_per_category(self):\n",
    "        try:\n",
    "            return self.dfTopEmo[0].value_counts().sort_index()\n",
    "        except:\n",
    "            return 'Top emo not defined'\n",
    "    \n",
    "    def plotConsistencyScore(self,y_axis='Score',ADD_OBSERVATION=False):           \n",
    "        def label_standards():\n",
    "            plt.title(y_axis)\n",
    "            plt.xlabel('Emotion categories',fontsize=16,labelpad=20); plt.xticks(fontsize=16,rotation=70)\n",
    "            plt.ylabel('Match score',fontsize=16)\n",
    "\n",
    "        def plot_horizonal_dashed_lines():\n",
    "            WEAK,MODERATE,STRONG=(0.2,0.4,0.7)\n",
    "            for yPOS in (WEAK,MODERATE,STRONG): plt.hlines(yPOS,-.5,DASHED_WIDTH,linestyles='dashed')\n",
    "\n",
    "        def label_consistency_on_the_right_margin():\n",
    "            CONSISTENCY_TEXT_X=DASHED_WIDTH+.2\n",
    "            consistencyLABELS= {'High':.85,'Moderate':.54,'Weak':.3,'None':.1}\n",
    "            plt.text(CONSISTENCY_TEXT_X,1.05,'Consistency',fontweight='bold',fontsize=16)\n",
    "            for LABEL,yPos in consistencyLABELS.items(): plt.text(CONSISTENCY_TEXT_X,yPos,LABEL,fontsize=16)\n",
    "\n",
    "        def set_y_axis_range_to_see_whistles_at_0_and_1(): return plt.ylim([-0.1,1.02])\n",
    "\n",
    "        ### MAIN PLOT   \n",
    "        dataframe = self.reliabilityScore\n",
    "        self.check_and_perform_analysis_('reliability')\n",
    "        \n",
    "        dataframe = self.reliabilityScore\n",
    "        y_axis=dataframe.columns[1]\n",
    "        \n",
    "        EMO_LIST_EKMAN=[emo for emo in np.sort(dataframe['EmotionCategory'].unique())]\n",
    "\n",
    "        DASHED_WIDTH=len(EMO_LIST_EKMAN)-.5\n",
    "        plt.figure(figsize=(15,4))\n",
    "\n",
    "        plot_horizonal_dashed_lines()\n",
    "\n",
    "        sns.boxplot(x='EmotionCategory',y=y_axis,data=dataframe,\n",
    "                   color='Grey',\n",
    "                    order=EMO_LIST_EKMAN #plot according to alphabetical order\n",
    "                   )\n",
    "\n",
    "        label_standards()        \n",
    "        label_consistency_on_the_right_margin()\n",
    "\n",
    "\n",
    "        set_y_axis_range_to_see_whistles_at_0_and_1()\n",
    "        \n",
    "        return self.reliabilityScore.groupby('EmotionCategory').describe().T\n",
    "        \n",
    "    \n",
    "    ##=========================================================================\n",
    "    @staticmethod\n",
    "    def __load_AU_data():   \n",
    "        def ____represent_pose_with_ActionUnit_pattern_retrievedFrom(dfSource):\n",
    "            AU_LIST=[str(i) for i in range(1,28)]   \n",
    "            AU_LIST_and_ID=AU_LIST + ['id']\n",
    "            df_AUs=dfSource[AU_LIST_and_ID].set_index('id')\n",
    "            df_AUs.index.name='survey_questions_id'\n",
    "            df_AUs=(df_AUs>=1)*1\n",
    "            return df_AUs.sort_index()\n",
    "        def transformAUpatternToAUlist(AUpattern): return [int(i) for i in AUpattern[AUpattern==1].index]\n",
    "        df_scenes=pd.read_csv('../data/core_data/survey_questions.csv')\n",
    "        df_AUs=____represent_pose_with_ActionUnit_pattern_retrievedFrom(df_scenes)\n",
    "        psAUlists=df_AUs.apply(lambda AUpattern: transformAUpatternToAUlist(AUpattern),axis=1)\n",
    "        dfAUlists=pd.DataFrame(psAUlists)\n",
    "        return dfAUlists\n",
    "    \n",
    "    @staticmethod\n",
    "    def __load_rating_data():\n",
    "        def __get_individualRatings_from(dataframe,condition='/survey-so'): return dataframe[dataframe['survey_condition']==condition]\n",
    "        \n",
    "        raw_ratings = pd.read_csv('../data/core_data/survey_data.csv')\n",
    "        return __get_individualRatings_from(raw_ratings)\n",
    "        \n",
    "    def __compute_604_times_13_matchscores(self,dfAUlists,METHOD,AU_PATTERN_TYPE,BinaryTHRES,v=True): \n",
    "        EMO_CAT = self.EMO_CAT\n",
    "        \n",
    "        dfT=dfAUlists.apply(\n",
    "            lambda row: pd.Series([self.matcher.compute_median_matchScore_across_stereotypeVariants(\n",
    "                    target=row[0],\n",
    "                    refEmoCat=EMO,\n",
    "                    method=METHOD,\n",
    "                ) for EMO in EMO_CAT]),\n",
    "            axis=1\n",
    "        )\n",
    "        dfT.columns=EMO_CAT\n",
    "        dfT.index.name=METHOD+'_'+AU_PATTERN_TYPE\n",
    "        return dfT\n",
    "    \n",
    "    ###    \n",
    "    \n",
    "    \n",
    "    def __compute_reliability_score(self):\n",
    "        r = pd.concat([self.dfTopEmo,self.matchScores],axis=1).apply(lambda row: pd.Series([row[0],row[row[0]]]),axis=1)\n",
    "        r.columns=['EmotionCategory',self.METHOD]\n",
    "        return r[r.index.isin(self.SELECTED)]\n",
    "    \n",
    "    def ____select_scenarios_with_minimum_rating_intensity(self):\n",
    "        dfToKeep=self.df_so.groupby('survey_questions_id').median()[self.EMO_CAT].apply(lambda row: row.max()>=self.RATING_INTENSITY,axis=1)\n",
    "        return dfToKeep[dfToKeep==True].index\n",
    "    \n",
    "    \n",
    "    def __get_2ndtopEmo(self,EMO_CAT = EMO_CAT):\n",
    "        def deepCopy_ensure_no_change_to(dfMedian): return pd.DataFrame.copy(dfMedian)\n",
    "        def remove_top_emo_by_setting_ratingValue_to_zero(row,dfTopEmo): row[dfTopEmo.loc[row.name]]=0; return row\n",
    "        def getMax(row):    return EMO_CAT[row[EMO_CAT].values.argmax()]\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            deepCopy_ensure_no_change_to(self.dfMedian)\\\n",
    "                    .apply(lambda row: remove_top_emo_by_setting_ratingValue_to_zero(row,self.dfTopEmo),axis=1)\\\n",
    "                    .apply(lambda row: getMax(row),axis=1)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def __get_topEmo(self):     \n",
    "        EMO_CAT = self.EMO_CAT\n",
    "        def get_assignment_based_on_highest_match_score(combined,number=False):\n",
    "            def getMax(row):\n",
    "                if(len(row.Assignment_based_on_highest_ratings)>1):\n",
    "                    if(sum(row[EMO_CAT].values==row[EMO_CAT].values.max())==1):\n",
    "                        return EMO_CAT[row[EMO_CAT].values.argmax()]\n",
    "                    else:\n",
    "                        return EMO_CAT[row[EMO_CAT].values==row[EMO_CAT].values.max()] if number else '---TIED---'\n",
    "                else:\n",
    "                    return row.Assignment_based_on_highest_ratings[0]\n",
    "\n",
    "            def extract_only_categories_tied_at_top(row): return row[row.Assignment_based_on_highest_ratings]\n",
    "\n",
    "            return pd.concat([\n",
    "                        combined['Assignment_based_on_highest_ratings'],\n",
    "                        combined.apply(lambda row: extract_only_categories_tied_at_top(row),axis=1).fillna(0)],axis=1\n",
    "                    )\\\n",
    "                         .apply(lambda row: getMax(row),axis=1)\n",
    "        \n",
    "\n",
    "        \n",
    "        combined = pd.concat([self.____get_emoList_based_on_maxMedian_minIQR(self.df_so),self.matchScores],axis=1)\n",
    "        \n",
    "        topEmo = get_assignment_based_on_highest_match_score(combined)\n",
    "        IND_TIED=topEmo[topEmo=='---TIED---'].index  \n",
    "        df_TIES = self.____break_ties(IND_TIED)\n",
    "\n",
    "        dfTopEmo=pd.DataFrame(topEmo)\n",
    "        dfTopEmo.loc[IND_TIED]=df_TIES\n",
    "        return dfTopEmo\n",
    "    \n",
    "    def __get_topEmo_basedOn_(self):     \n",
    "        EMO_CAT = self.EMO_CAT\n",
    "        def get_assignment_based_on_highest_match_score(combined,number=False):\n",
    "            def getMax(row):\n",
    "                if(len(row.Assignment_based_on_highest_ratings)>1):\n",
    "                    if(sum(row[EMO_CAT].values==row[EMO_CAT].values.max())==1):\n",
    "                        return EMO_CAT[row[EMO_CAT].values.argmax()]\n",
    "                    else:\n",
    "                        return EMO_CAT[row[EMO_CAT].values==row[EMO_CAT].values.max()] if number else '---TIED---'\n",
    "                else:\n",
    "                    return row.Assignment_based_on_highest_ratings[0]\n",
    "\n",
    "            def extract_only_categories_tied_at_top(row): return row[row.Assignment_based_on_highest_ratings]\n",
    "\n",
    "            return pd.concat([\n",
    "                        combined['Assignment_based_on_highest_ratings'],\n",
    "                        combined.apply(lambda row: extract_only_categories_tied_at_top(row),axis=1).fillna(0)],axis=1\n",
    "                    )\\\n",
    "                         .apply(lambda row: getMax(row),axis=1)\n",
    "        \n",
    "\n",
    "        \n",
    "        combined = pd.concat([self.____get_emoList_based_on_maxMedian_minIQR_maxMean_minStd(self.df_so),self.matchScores],axis=1)\n",
    "        \n",
    "        topEmo = get_assignment_based_on_highest_match_score(combined)\n",
    "        IND_TIED=topEmo[topEmo=='---TIED---'].index  \n",
    "        df_TIES = self.____break_ties(IND_TIED)\n",
    "\n",
    "        dfTopEmo=pd.DataFrame(topEmo)\n",
    "        dfTopEmo.loc[IND_TIED]=df_TIES\n",
    "        return dfTopEmo\n",
    "    \n",
    "    def get_topEmo_randomly_when_tied(self):     \n",
    "        return self.____get_emoList_based_on_maxMedian_minIQR(self.df_so)\\\n",
    "#             .applymap(lambda emoList: np.random.choice(emoList))\n",
    "    \n",
    "    def ____break_ties(self,IND_TIED): \n",
    "        return pd.DataFrame(\n",
    "            self.____get_emoList_based_on_maxMedian_minIQR_maxMean_minStd(self.df_so[self.df_so.survey_questions_id.isin(IND_TIED)]).loc[IND_TIED]\\\n",
    "                .apply(lambda row: row.Assignment_based_on_highest_ratings[0],axis=1)\n",
    "        )\n",
    "    \n",
    "    def ____get_emoList_based_on_maxMedian_minIQR(self,df_so):\n",
    "        dat2={survey_questions_id : self.______getMinIQRCategories(df_so,survey_questions_id,self.______getMaxMedianCategories(df_so,survey_questions_id)) \n",
    "         for survey_questions_id in np.unique(df_so['survey_questions_id'].values)}\n",
    "\n",
    "        dat22=pd.DataFrame(pd.Series(dat2))\n",
    "        dat22.columns=['Assignment_based_on_highest_ratings']\n",
    "        return dat22\n",
    "\n",
    "    def ____get_emoList_based_on_maxMedian_minIQR_maxMean_minStd(self,df_so):\n",
    "        dat2={survey_questions_id : \n",
    "              self.______getMinSTDCategories(df_so,survey_questions_id,\n",
    "                  self.______getMaxMeanCategories(df_so,survey_questions_id,\n",
    "                    self.______getMinIQRCategories(df_so,survey_questions_id,\n",
    "                        self.______getMaxMedianCategories(df_so,survey_questions_id)))) \n",
    "         for survey_questions_id in np.unique(df_so['survey_questions_id'].values)}\n",
    "\n",
    "        dat22=pd.DataFrame(pd.Series(dat2))\n",
    "        dat22.columns=['Assignment_based_on_highest_ratings']\n",
    "        return dat22\n",
    "    \n",
    "    def ____get_emoList_based_on_maxMedian_minIQR_maxMean(self,df_so):\n",
    "        dat2={survey_questions_id : \n",
    "              self.______getMaxMeanCategories(df_so,survey_questions_id,\n",
    "                self.______getMinIQRCategories(df_so,survey_questions_id,\n",
    "                    self.______getMaxMedianCategories(df_so,survey_questions_id))) \n",
    "         for survey_questions_id in np.unique(df_so['survey_questions_id'].values)}\n",
    "\n",
    "        dat22=pd.DataFrame(pd.Series(dat2))\n",
    "        dat22.columns=['Assignment_based_on_highest_ratings']\n",
    "        return dat22\n",
    "    \n",
    "    @staticmethod\n",
    "    def ______getMaxMedianCategories(df,survey_questions_id,selectedCategory=EMO_CAT): \n",
    "        def get_maxMedian(df,survey_questions_id): return df[df.survey_questions_id==survey_questions_id][selectedCategory].median()==df[df.survey_questions_id==survey_questions_id][selectedCategory].median().max()\n",
    "\n",
    "        maxMedian = get_maxMedian(df,survey_questions_id)\n",
    "        return [i for i in maxMedian.index if maxMedian[i]]\n",
    "\n",
    "    @staticmethod\n",
    "    def ______getMinIQRCategories(df,survey_questions_id,selectedCategory=EMO_CAT):\n",
    "        iqr = df[df.survey_questions_id==survey_questions_id][selectedCategory].apply(lambda col: np.quantile(col,.75)-np.quantile(col,.25),axis=0)\n",
    "        minIQR = (iqr==iqr.min())\n",
    "        return [i for i in minIQR.index if minIQR[i]]\n",
    "\n",
    "    @staticmethod\n",
    "    def ______getMaxMeanCategories(df,survey_questions_id,selectedCategory=EMO_CAT):\n",
    "        def get_maxMean(df,survey_questions_id): return df[df.survey_questions_id==survey_questions_id][selectedCategory].mean()==df[df.survey_questions_id==survey_questions_id][selectedCategory].mean().max()\n",
    "\n",
    "        maxMean = get_maxMean(df,survey_questions_id)\n",
    "        return [i for i in maxMean.index if maxMean[i]]    \n",
    "\n",
    "    @staticmethod\n",
    "    def ______getMinSTDCategories(df,survey_questions_id,selectedCategory=EMO_CAT):\n",
    "        std= df[df.survey_questions_id==survey_questions_id][selectedCategory].std()\n",
    "        minStd=(std==std.min() )\n",
    "        return [i for i in minStd.index if minStd[i]]\n",
    "    \n",
    "    \n",
    "    ###      \n",
    "    def generate_reliability_statistics_for_figure_3(self):\n",
    "        self.check_and_perform_analysis_('reliability')\n",
    "        return self.reliabilityScore.groupby('EmotionCategory').describe().T\n",
    "    \n",
    "    def generate_table_S7_reliabilityScore(self):\n",
    "        self.check_and_perform_analysis_('reliability')\n",
    "        \n",
    "        def get_percent(row): return np.round(row.values/row.sum(),2)\n",
    "        def get_total(row): return row.sum()\n",
    "        \n",
    "        t = self.__generate_table_count_consistency_category()\n",
    "        index = [n+'(proportion)' for n in t.columns]\n",
    "\n",
    "        \n",
    "        def get_ordered_column(CAT): \n",
    "            l = []; \n",
    "            for i,c in enumerate(CAT): \n",
    "                l.append(c);l.append(index[i]); \n",
    "            return l\n",
    "            \n",
    "        df= pd.concat([\n",
    "            t,\n",
    "            t.apply(lambda row: pd.Series(get_percent(row),index=index),axis=1),\n",
    "            t.apply(lambda row: pd.Series(get_total(row),index=['total']),axis=1),\n",
    "        ],axis=1)\n",
    "        \n",
    "        return df[get_ordered_column(self.CATEGORY)]\n",
    "        \n",
    "    def __generate_table_count_consistency_category(self,CATEGORY=CATEGORY):\n",
    "        g=self.reliabilityScore.set_index('EmotionCategory')\\\n",
    "            .applymap(lambda val: self.____assign_consistency_category(val))\\\n",
    "            .reset_index().groupby('EmotionCategory')\n",
    "        return g[self.METHOD].value_counts().unstack().fillna(0).astype(int)[CATEGORY]\n",
    "        \n",
    "    @staticmethod\n",
    "    def ____assign_consistency_category(val):\n",
    "        if(val < 0.2): return 'None'\n",
    "        elif(val < 0.4 and val >=0.2): return 'Weak'\n",
    "        elif(val < 0.7 and val >= 0.4): return 'Moderate'\n",
    "        elif(val >= 0.7): return 'Strong'\n",
    "        else: return 'Error'\n",
    "\n",
    "    def ____test_assign_consistency_category(self):\n",
    "        assert(self.____assign_consistency_category(0.1)=='None')\n",
    "        assert(self.____assign_consistency_category(0.2)=='Weak')\n",
    "        assert(self.____assign_consistency_category(0.4)=='Moderate')\n",
    "        assert(self.____assign_consistency_category(0.7)=='Strong')\n",
    "\n",
    "\n",
    "    ##\n",
    "    def generate_table_S8_BayesFactor(self):\n",
    "        self.check_and_perform_analysis_('reliability')\n",
    "        \n",
    "        consistencyTabe = self.__generate_table_count_consistency_category()\n",
    "        table=consistencyTabe.apply(lambda s: self.__compute_bayesFactor_and_significant_pairwise(s),axis=1)\n",
    "        return table.applymap(lambda val: self.__formatTable(val))\n",
    "\n",
    "    @staticmethod\n",
    "    def __formatTable(data):\n",
    "        SIGNIFICANT,BayesVal=(data['significant'],data['bayes_factor'])\n",
    "\n",
    "        if(SIGNIFICANT):\n",
    "            if(BayesVal>1000): return '>1000***'\n",
    "            elif(BayesVal>100):return '{:.2f}***'.format(BayesVal)\n",
    "            elif(BayesVal>30): return '{:.2f}**'.format(BayesVal)\n",
    "            elif(BayesVal>10): return '{:.2f}*'.format(BayesVal)\n",
    "            else:              return '{:.2f}'.format(BayesVal)\n",
    "        else:\n",
    "            if(BayesVal>1000): return '>1000'\n",
    "            else:              return '{:.2f}'.format(BayesVal)\n",
    "\n",
    "    def __compute_bayesFactor_and_significant_pairwise(self,s):\n",
    "        n=s.sum()\n",
    "        testResult=[];label=[]\n",
    "        for i in range(0,len(s.index)):\n",
    "            for j in range(i+1,len(s.index)):\n",
    "                k1=s[i];k2=s[j];n1=n2=n\n",
    "                testResult.append(self.____test_first_distributions_greater(k1,n1,k2,n2))\n",
    "                label.append(s.index[i] + '>' + s.index[j])          \n",
    "        return pd.Series(testResult,index=label)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ____test_first_distributions_greater(k1,n1,k2,n2,numSamp=10000,sigLevel=0.05,BayesFactorThres=0.5,v=False):\n",
    "        '''\n",
    "            Reference: Bayes factor ~ likelihood ratio http://statmath.wu.ac.at/research/talks/resources/talkheld.pdf\n",
    "        '''\n",
    "        def sample_betaDist(k,n,numSamp=1000,v=False): alpha=k+1;beta=n-k+1; return np.random.beta(alpha,beta,numSamp)\n",
    "        def simulate_two_beta_distributions(k1,n1,k2,n2,numSamp=numSamp): return (sample_betaDist(k1,n1,numSamp),sample_betaDist(k2,n2,numSamp))      \n",
    "        def compute_difference_between_a_pair_of_sample_from_each_distribution(s1,s2): return s1 - s2\n",
    "        def compute_probability_s1_greater_s2(differenceDistribution,numSamp=numSamp): return np.sum(differenceDistribution>0)/numSamp  \n",
    "        def compute_bayes_factor(s1,s2,DIV_BY_ZERO_CORRECTION = 1e-14): return np.sum(s1>BayesFactorThres)/(np.sum(s2>BayesFactorThres)+DIV_BY_ZERO_CORRECTION)    \n",
    "        def compute_significant_either_direction(prob,sigLevel): return prob>(1-sigLevel) # or (prob < sigLevel)\n",
    "\n",
    "        s1,s2 = simulate_two_beta_distributions(k1,n1,k2,n2) \n",
    "        sD=compute_difference_between_a_pair_of_sample_from_each_distribution(s1,s2); plt.hist(sD) if(v) else '';\n",
    "        prob = compute_probability_s1_greater_s2(sD)\n",
    "\n",
    "        return {\n",
    "            'bayes_factor' : compute_bayes_factor(s1,s2),\n",
    "            'prob'         : prob,\n",
    "            'significant'  : compute_significant_either_direction(prob,sigLevel)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========== SPECIFICITY ANALYSIS \n",
    "    def __assign_poses_into_emotion_category_by_AUstereotypes_into_dict_of_dataframes(self,faceDataframe,SPECIFICITY_THRESHOLD):\n",
    "        def retain_unique_set_of_matching_poses_by_removing_overlaps(inputDataframe):\n",
    "            df = inputDataframe.drop_duplicates(subset=None, keep='first')\n",
    "            return df.astype('int32')\n",
    "\n",
    "        def combineDataframe(dataframe):\n",
    "            dfTemp=pd.DataFrame()\n",
    "            for key,value in dataframe.items():\n",
    "                dfTemp=pd.concat([dfTemp,pd.Series(value.index)])  \n",
    "            return dfTemp \n",
    "\n",
    "        dfU=dict()\n",
    "        for emoCat,PATTERN in self.REF_AU_VEC.items():       \n",
    "            dfVar = self.____pick_matching_poses_forEach_AUstereotypes_variants(faceDataframe,PATTERN,SPECIFICITY_THRESHOLD)  \n",
    "            dfU[emoCat] = retain_unique_set_of_matching_poses_by_removing_overlaps(combineDataframe(dfVar))\n",
    "            \n",
    "        return dfU\n",
    "    \n",
    "    def ____pick_matching_poses_forEach_AUstereotypes_variants(self,faceAUsDataframe,EACH_STEREOTYPE,SPECIFICITY_THRESHOLD,v=False):\n",
    "        dfT2=dict(); AU_PATTERN_COLUMN=0\n",
    "        for index,VARIANT in EACH_STEREOTYPE.items():\n",
    "            def compute_match_score_for_all_poses_against_variant(df,VARIANT): return df.apply(\n",
    "                lambda AUpattern: self.matcher.compute_matchScore(AUpattern[AU_PATTERN_COLUMN],VARIANT,method=self.METHOD),axis=1)  \n",
    "            def extractSubsetMeetingThreshold(pdSeries,SPECIFICITY_THRESHOLD): return pdSeries[pdSeries>=SPECIFICITY_THRESHOLD]\n",
    "\n",
    "            print('iPattern,VARIATION_PATTERN =',VARIANT) if(v) else ''\n",
    "            dfT1=compute_match_score_for_all_poses_against_variant(faceAUsDataframe,VARIANT)    \n",
    "            dfT2[index]=extractSubsetMeetingThreshold(dfT1,SPECIFICITY_THRESHOLD)\n",
    "        return dfT2\n",
    "    \n",
    "\n",
    "    def __assign_true_if_pose_specific_to_assignged_emotion_category_into_dict_of_booleanDataframes(self,dict_of_dataframes,dfMedianRating):\n",
    "        d=dict(); dict_Dfs = dict_of_dataframes\n",
    "        for emoCat in self.REF_AU_VEC.keys():\n",
    "            d[emoCat]=dfMedianRating.loc[dict_Dfs[emoCat][0].values].apply(\n",
    "                lambda row: self.____is_pose_NOT_specific_to_assigned_emotion_category(emoCat, row)*1,\n",
    "                axis=1\n",
    "            )\n",
    "        return d\n",
    "    \n",
    "    @staticmethod\n",
    "    def ____is_pose_NOT_specific_to_assigned_emotion_category(assignedCategory,poseMedianScenarioRatings):\n",
    "        c,m=(assignedCategory,poseMedianScenarioRatings)\n",
    "        def is_rating_of_assigned_emotion_category_BELOW(c,m,t): return poseMedianScenarioRatings[c] <= t\n",
    "        def is_rating_of_another_emotion_category_ATLEAST(m,t): return sum(m>t) > 0\n",
    "        return is_rating_of_assigned_emotion_category_BELOW(c,m,2) and is_rating_of_another_emotion_category_ATLEAST(m,2)\n",
    "    \n",
    "    def __compute_specificity_statistics_into_dataframe(self,dict_of_booleanDataframes):\n",
    "        d=dict();bool_Dfs=dict_of_booleanDataframes\n",
    "        for EMO,dfBool in bool_Dfs.items():\n",
    "            returnNull = len(dfBool)==0\n",
    "            k=dfBool.sum()\n",
    "            n=dfBool.count()\n",
    "            d[EMO]=self.____computeP_sig(n-k,n,returnNull=returnNull)\n",
    "        return pd.DataFrame(d).T\n",
    "\n",
    "    @staticmethod\n",
    "    def ____computeP_sig(k,n,method='Bayesian',chance_level=0.167,lowerBound=True,returnNull=False):\n",
    "\n",
    "        def compute_statistics_method_Bayesian(k,n):\n",
    "            def gen_betaDist_samples(k,n,numSamp=1000,v=False): alpha=k+1;beta=n-k+1; return np.random.beta(alpha,beta,numSamp)\n",
    "            def obtain_creditabilityInterval_bounds(): return tuple(np.percentile(samp,[2.5,97.5]))\n",
    "            def obtain_mean_estimate(): return np.percentile(samp,50)\n",
    "\n",
    "            samp=gen_betaDist_samples(k,n,numSamp=10000)\n",
    "            p_hat=obtain_mean_estimate()\n",
    "            CI_lower,CI_upper=obtain_creditabilityInterval_bounds()\n",
    "            return p_hat,CI_lower,CI_upper\n",
    "\n",
    "        def compute_statistics_method_Binomial(k,n):\n",
    "            p_hat=k/n\n",
    "            CI_dev=np.sqrt(p_hat*(1-p_hat)/n)\n",
    "            CI_lower=(p_hat-CI_dev,p_hat+CI_dev)\n",
    "\n",
    "        compute_statistics={\n",
    "            'Bayesian': compute_statistics_method_Bayesian,\n",
    "            'Binomial': compute_statistics_method_Binomial,\n",
    "        }\n",
    "\n",
    "        def computeP(k,n,method='Bayesian',v=False):\n",
    "            ''' @param: method='Bayesian' or 'Binomial' '''\n",
    "            p_hat,CI_lower,CI_upper=compute_statistics[method](k,n)\n",
    "            return {'k':k,'n':n,'p_hat':round(p_hat,2),'CI_lower':round(CI_lower,2),'CI_upper':round(CI_upper,2)}\n",
    "\n",
    "\n",
    "        def determineSignificance(CI_lower,chance_level=0.167): return CI_lower>chance_level\n",
    "\n",
    "        ##\n",
    "        if(returnNull): \n",
    "            return {'k': -1,'n':-1,'p_hat':-1,'CI_lower':-1,'CI_upper':-1,'significant':-1}\n",
    "        else:\n",
    "            result=computeP(k,n,method=method)\n",
    "            result['significant']=determineSignificance(result['CI_lower'])*1\n",
    "            return pd.Series(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter():        \n",
    "    def plotConsistencyScore(self,dataframe,y_axis='Score',ADD_OBSERVATION=False,figsize=(15,4)):             \n",
    "        return self.plot(dataframe,y_axis=y_axis,ADD_OBSERVATION=ADD_OBSERVATION,figsize=figsize)\n",
    "    \n",
    "    def plotSpecificityScore(self,df,EMO_LIST):\n",
    "        dfToPlot = df[df.index.isin(EMO_LIST)]\n",
    "        plt.vlines(dfToPlot.index,dfToPlot.CI_lower,dfToPlot.CI_upper,color='#ED7D31',linewidth=1.5,alpha=1)  \n",
    "        plt.scatter(dfToPlot.index,dfToPlot.p_hat,\n",
    "                    marker='d',color='#ED7D31',edgecolors='black',linewidth=1,s=200,alpha=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot(self,dataframe,y_axis='Score',ADD_OBSERVATION=False,emotionCategories=None,figsize=(15,4)):           \n",
    "        ### MAIN PLOT   \n",
    "        if(emotionCategories is None): \n",
    "            df = dataframe\n",
    "            EMO_LIST_EKMAN=[emo for emo in np.sort(df['EmotionCategory'].unique())]\n",
    "\n",
    "        else:\n",
    "            EMO_LIST_EKMAN=emotionCategories \n",
    "            df = df[df['EmotionCategory'].isin(emotionCategories)]\n",
    "\n",
    "        DASHED_WIDTH=len(EMO_LIST_EKMAN)-.5\n",
    "        plt.figure(figsize=(len(EMO_LIST_EKMAN)*2,4*2))\n",
    "\n",
    "        self.plot_horizonal_dashed_lines(DASHED_WIDTH)\n",
    "\n",
    "        sns.boxplot(\n",
    "            x='EmotionCategory',\n",
    "            y=y_axis,\n",
    "            data=df,\n",
    "            boxprops=dict(alpha=1),\n",
    "            color='#D3D3D3',\n",
    "            order=EMO_LIST_EKMAN #plot according to alphabetical order\n",
    "        )\n",
    "        \n",
    "        self.label_standards(TITLE='')        \n",
    "        self.label_consistency_on_the_right_margin(DASHED_WIDTH)\n",
    "\n",
    "\n",
    "        self.set_y_axis_range_to_see_whistles_at_0_and_1()\n",
    "        \n",
    "        return dataframe.describe().T\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_boxplot(data):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_horizonal_dashed_lines(DASHED_WIDTH):\n",
    "        WEAK,MODERATE,STRONG=(0.2,0.4,0.7)\n",
    "        for yPOS in (WEAK,MODERATE,STRONG): plt.hlines(yPOS,-.5,DASHED_WIDTH,linestyles='dashed',color='black')\n",
    "\n",
    "    @staticmethod\n",
    "    def label_consistency_on_the_right_margin(DASHED_WIDTH):\n",
    "        CONSISTENCY_TEXT_X=DASHED_WIDTH+.2\n",
    "        consistencyLABELS= {'High':.85,'Moderate':.54,'Weak':.3,'None':.1}\n",
    "        plt.text(CONSISTENCY_TEXT_X,1.05,'Consistency',fontweight='bold',fontsize=16)\n",
    "        for LABEL,yPos in consistencyLABELS.items(): plt.text(CONSISTENCY_TEXT_X,yPos,LABEL,fontsize=16)\n",
    "      \n",
    "    @staticmethod\n",
    "    def set_y_axis_range_to_see_whistles_at_0_and_1(): return plt.ylim([-0.1,1.02])\n",
    "    \n",
    "    @staticmethod\n",
    "    def label_standards(TITLE='PlotTitle'):\n",
    "            plt.title(TITLE)\n",
    "            plt.xlabel('Emotion categories',fontsize=16,labelpad=20); plt.xticks(fontsize=16*2,rotation=40)\n",
    "            plt.ylabel('Match score',fontsize=16*2)\n",
    "            plt.xticks(fontsize=16)\n",
    "            plt.yticks(fontsize=16)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Analyzer(\n",
    "    AU_PATTERN_TYPE='all_patterns_all_variants',\n",
    "    METHOD='method1_sim_addAU',\n",
    "    TIE_BREAKER_MATCH_SCORE=True,\n",
    "    USE_2nd_TOP_CATEGORY=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing analysis:  reliability\n"
     ]
    }
   ],
   "source": [
    "a.generate_reliability_statistics_for_figure_3()\n",
    "a.generate_table_S7_reliabilityScore()\n",
    "a.generate_table_S8_BayesFactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_EMO = a.reliabilityScore.EmotionCategory.unique()\n",
    "EMO_CAT = ['Amusement','Embarrassment','Pride','Shame']\n",
    "EMO_CAT_standard = list(set(ALL_EMO)-set(EMO_CAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=a.reliabilityScore[a.reliabilityScore.EmotionCategory.isin(EMO_CAT)]\n",
    "dfs = a.reliabilityScore[a.reliabilityScore.EmotionCategory.isin(EMO_CAT_standard)]\n",
    "dfSpecificity=a.perform_specificity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter().plotConsistencyScore(dfs,y_axis='method1_sim_addAU')\n",
    "Plotter().plotSpecificityScore(dfSpecificity,EMO_CAT_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter().plotConsistencyScore(df,y_axis='method1_sim_addAU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
